{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73c22081-80af-40ab-958d-4cc227f96baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2038c9e-813e-44bb-9f9a-13d47ff78088",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded GraiStoc-06-29-2001.txt to USDA_Reports\\GraiStoc-06-29-2001.txt\n",
      "Downloaded GraiStoc-03-30-2001.txt to USDA_Reports\\GraiStoc-03-30-2001.txt\n",
      "Downloaded GraiStoc-01-11-2001.txt to USDA_Reports\\GraiStoc-01-11-2001.txt\n",
      "Downloaded GraiStoc-09-29-2000.txt to USDA_Reports\\GraiStoc-09-29-2000.txt\n",
      "Downloaded GraiStoc-06-30-2000.txt to USDA_Reports\\GraiStoc-06-30-2000.txt\n",
      "Downloaded GraiStoc-03-31-2000.txt to USDA_Reports\\GraiStoc-03-31-2000.txt\n",
      "Downloaded GraiStoc-01-12-2000.txt to USDA_Reports\\GraiStoc-01-12-2000.txt\n",
      "Downloaded GraiStoc-09-30-1999.txt to USDA_Reports\\GraiStoc-09-30-1999.txt\n",
      "Downloaded GraiStoc-06-30-1999.txt to USDA_Reports\\GraiStoc-06-30-1999.txt\n",
      "Downloaded GraiStoc-03-31-1999.txt to USDA_Reports\\GraiStoc-03-31-1999.txt\n",
      "Downloaded grst0323.txt to USDA_Reports\\grst0323.txt\n"
     ]
    }
   ],
   "source": [
    "# set the URL of the page with reports\n",
    "url = 'https://usda.library.cornell.edu/concern/publications/xg94hp534?locale=en&page=10#release-items'\n",
    "\n",
    "# send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# parse the HTML content of the response using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# find all the file download links that end with \".txt\"\n",
    "txt_links = [link['href'] for link in soup.find_all('a', {'class': 'file_download'}) if link['href'].endswith('.txt')]\n",
    "\n",
    "# create a directory to store the downloaded files\n",
    "if not os.path.exists('USDA_Reports'):\n",
    "    os.makedirs('USDA_Reports')\n",
    "\n",
    "# download each TXT file and save it in the directory\n",
    "for link in txt_links:\n",
    "    file_name = link.split('/')[-1]\n",
    "    file_path = os.path.join('USDA_Reports', file_name)\n",
    "    response = requests.get(link)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "        print(f'Downloaded {file_name} to {file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd24fbce-7487-4a11-9a05-8c52743ae3a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded cpvl0223.txt to USDA_Crop Values Annual Summary Reports\\cpvl0223.txt\n",
      "Downloaded cpvl0222.txt to USDA_Crop Values Annual Summary Reports\\cpvl0222.txt\n",
      "Downloaded cpvl0221.txt to USDA_Crop Values Annual Summary Reports\\cpvl0221.txt\n",
      "Downloaded cpvl0220.txt to USDA_Crop Values Annual Summary Reports\\cpvl0220.txt\n",
      "Downloaded cpvl0419.txt to USDA_Crop Values Annual Summary Reports\\cpvl0419.txt\n",
      "Downloaded 02-6-19_Report_Reschedule_Final3.txt to USDA_Crop Values Annual Summary Reports\\02-6-19_Report_Reschedule_Final3.txt\n",
      "Downloaded CropValuSu-02-23-2018.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-23-2018.txt\n",
      "Downloaded CropValuSu-02-24-2017.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-24-2017.txt\n",
      "Downloaded CropValuSu-02-24-2016.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-24-2016.txt\n",
      "Downloaded CropValuSu-02-24-2015_correction.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-24-2015_correction.txt\n",
      "Downloaded cpvl0223.txt to USDA_Crop Values Annual Summary Reports\\cpvl0223.txt\n",
      "Downloaded CropValuSu-02-14-2014.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-14-2014.txt\n",
      "Downloaded CropValuSu-02-15-2013.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-15-2013.txt\n",
      "Downloaded CropValuSu-02-16-2012.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-16-2012.txt\n",
      "Downloaded CropValuSu-02-16-2011.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-16-2011.txt\n",
      "Downloaded CropValuSu-02-19-2010.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-19-2010.txt\n",
      "Downloaded CropValuSu-02-13-2009.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-13-2009.txt\n",
      "Downloaded CropValuSu-02-14-2008.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-14-2008.txt\n",
      "Downloaded CropValuSu-02-15-2007.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-15-2007.txt\n",
      "Downloaded CropValuSu-02-15-2006.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-15-2006.txt\n",
      "Downloaded CropValuSu-06-10-2005.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-06-10-2005.txt\n",
      "Downloaded cpvl0223.txt to USDA_Crop Values Annual Summary Reports\\cpvl0223.txt\n",
      "Downloaded CropValuSu-03-31-2004.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-03-31-2004.txt\n",
      "Downloaded CropValuSu-02-13-2003.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-13-2003.txt\n",
      "Downloaded CropValuSu-02-20-2002.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-20-2002.txt\n",
      "Downloaded CropValuSu-02-15-2001.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-15-2001.txt\n",
      "Downloaded CropValuSu-02-11-2000.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-11-2000.txt\n",
      "Downloaded CropValuSu-02-12-1999.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-12-1999.txt\n",
      "Downloaded CropValuSu-02-13-1998.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-13-1998.txt\n",
      "Downloaded CropValuSu-02-14-1997.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-14-1997.txt\n",
      "Downloaded CropValuSu-02-15-1996.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-02-15-1996.txt\n",
      "Downloaded cpvl0223.txt to USDA_Crop Values Annual Summary Reports\\cpvl0223.txt\n",
      "Downloaded CropValuSu-01-25-1995.txt to USDA_Crop Values Annual Summary Reports\\CropValuSu-01-25-1995.txt\n",
      "Downloaded cpvl0223.txt to USDA_Crop Values Annual Summary Reports\\cpvl0223.txt\n",
      "Downloaded cpvl0223.txt to USDA_Crop Values Annual Summary Reports\\cpvl0223.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# set the base URL of the page with reports\n",
    "base_url = 'https://usda.library.cornell.edu/concern/publications/k35694332'\n",
    "\n",
    "# loop through pages 1 to the end of the page\n",
    "for page in range(1, 6):\n",
    "    # set the URL of the current page\n",
    "    url = f'{base_url}?locale=en&page={page}#release-items'\n",
    "\n",
    "    # send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # parse the HTML content of the response using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # find all the file download links that end with \".txt\"\n",
    "    txt_links = [link['href'] for link in soup.find_all('a', {'class': 'file_download'}) if link['href'].endswith('.txt')]\n",
    "\n",
    "    # create a directory to store the downloaded files\n",
    "    if not os.path.exists('USDA_Crop Values Annual Summary Reports'):\n",
    "        os.makedirs('USDA_Crop Values Annual Summary Reports')\n",
    "\n",
    "    # download each TXT file and save it in the directory\n",
    "    for link in txt_links:\n",
    "        file_name = link.split('/')[-1]\n",
    "        file_path = os.path.join('USDA_Crop Values Annual Summary Reports', file_name)\n",
    "        response = requests.get(link)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "            print(f'Downloaded {file_name} to {file_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
